{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "552acc7c-2516-4c5d-bc9a-20a23d17bb70",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd1b3065-2b02-4632-b0cf-5304828c3d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3b8c55f-9e03-417b-9dc9-20de76f9e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector DB\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, ChatHuggingFace, HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d793c367-9c02-41fc-9f95-0ae68acca164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat\n",
    "import torch\n",
    "from langchain_openai import ChatOpenAI\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6de70850-99fb-4ed7-b1cc-61b841cb30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSOLUTE_PATH = os.path.abspath(os.getcwd())\n",
    "VDB_PATH = os.path.join(ABSOLUTE_PATH, \"VectorDBs\")\n",
    "\n",
    "def set_path(db_name: str, vdb_path: str=VDB_PATH) -> str:\n",
    "    return os.path.join(vdb_path, db_name)\n",
    "\n",
    "# Chroma vector store paths\n",
    "CHROMADB_OPENAI_PATH = set_path(\"insurellm_chroma_vector_db\")\n",
    "CHROMADB_HF_PATH = set_path(\"insurellm_chroma_vector_db_hf\")\n",
    "\n",
    "# FAISS vector store paths\n",
    "FAISSDB_OPENAI_PATH = set_path(\"insurellm_faiss_vector_db\")\n",
    "FAISSDB_HF_PATH = set_path(\"insurellm_faiss_vector_db_hf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fdf170-249a-4ff5-be2d-429cfc454f32",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a86dfc0e-ee26-47cf-9927-01a7803a392b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings are loaded.\n"
     ]
    }
   ],
   "source": [
    "# OpenAI Embeddings\n",
    "load_dotenv(override=True)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"type-your-api-key-here\")\n",
    "openai_embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Hugging Face Embeddings\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\", \"type-your-token-here\")\n",
    "login(HF_TOKEN)\n",
    "hf_embeddings = HuggingFaceEmbeddings(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "if openai_embeddings and hf_embeddings:\n",
    "    print(\"Embeddings are loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aa990d-6cf4-47ed-a472-58ff330dc8c5",
   "metadata": {},
   "source": [
    "# Load Vector Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f860d3e-02d3-4e89-bd60-e2207d656e64",
   "metadata": {},
   "source": [
    "## Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47d8f700-cf23-498e-b3cf-6b3c45d99363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading D:\\Learn\\LLM\\llm_engineering\\week5\\VectorDBs\\insurellm_chroma_vector_db vector stores ...\n",
      "D:\\Learn\\LLM\\llm_engineering\\week5\\VectorDBs\\insurellm_chroma_vector_db vector stores are loaded: 123 documents found.\n",
      "\n",
      "Loading D:\\Learn\\LLM\\llm_engineering\\week5\\VectorDBs\\insurellm_chroma_vector_db_hf vector stores ...\n",
      "D:\\Learn\\LLM\\llm_engineering\\week5\\VectorDBs\\insurellm_chroma_vector_db_hf vector stores are loaded: 123 documents found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_chroma_vdb(db_path: str, embeddings) -> Chroma:\n",
    "    if os.path.exists(db_path):\n",
    "        print(f\"Loading {db_path} vector stores ...\")\n",
    "        vectorstores = Chroma(persist_directory=db_path, embedding_function=embeddings)\n",
    "        num_docs = vectorstores._collection.count()\n",
    "        print(f\"{db_path} vector stores are loaded: {num_docs} documents found.\\n\")\n",
    "        return vectorstores\n",
    "    else:\n",
    "        print(f\"{db_path} not found in directory.\\n\")\n",
    "\n",
    "chroma_openai_vectorstores = load_chroma_vdb(CHROMADB_OPENAI_PATH, openai_embeddings)\n",
    "chroma_hf_vectorstores = load_chroma_vdb(CHROMADB_HF_PATH, hf_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4169fe-37e5-44e2-8015-e5678f08609f",
   "metadata": {},
   "source": [
    "## FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e92acf73-d171-4b36-a5d3-7983804d6c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading D:\\Learn\\LLM\\llm_engineering\\week5\\VectorDBs\\insurellm_faiss_vector_db vector stores ...\n",
      "D:\\Learn\\LLM\\llm_engineering\\week5\\VectorDBs\\insurellm_faiss_vector_db vector stores are loaded.\n",
      "Found 123 documents with 1536 dimensions.\n",
      "\n",
      "Loading D:\\Learn\\LLM\\llm_engineering\\week5\\VectorDBs\\insurellm_faiss_vector_db_hf vector stores ...\n",
      "D:\\Learn\\LLM\\llm_engineering\\week5\\VectorDBs\\insurellm_faiss_vector_db_hf vector stores are loaded.\n",
      "Found 123 documents with 384 dimensions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_faiss_db(db_path: str, embeddings) -> FAISS:\n",
    "    if os.path.exists(db_path):\n",
    "        print(f\"Loading {db_path} vector stores ...\")\n",
    "        vectorstores = FAISS.load_local(db_path, embeddings=embeddings, allow_dangerous_deserialization=True)\n",
    "        num_docs = vectorstores.index.ntotal\n",
    "        dim = vectorstores.index.d\n",
    "        print(f\"{db_path} vector stores are loaded.\")\n",
    "        print(f\"Found {num_docs} documents with {dim} dimensions.\\n\")\n",
    "        return vectorstores\n",
    "    else:\n",
    "        print(f\"{db_path} not found in directory.\\n\")\n",
    "\n",
    "faiss_openai_vectorstores = load_faiss_db(FAISSDB_OPENAI_PATH, openai_embeddings)\n",
    "faiss_hf_vectorstores = load_faiss_db(FAISSDB_HF_PATH, hf_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7d80f1-26fa-4f11-9e93-bcc2f9950fe7",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6bef34d-663a-49cc-91b4-d310d50ba736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ollama model\n",
    "OLLAMA_API_KEY = \"ollama\"\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "llama_model = \"llama3.2:latest\"\n",
    "\n",
    "# GPT model\n",
    "gpt_model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b0a9535-906a-450a-bf6f-479721288a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face model and its tokenizer are loaded.\n",
      "CPU times: total: 4.39 s\n",
      "Wall time: 6.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Hugging Face Model\n",
    "hf_model = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "# 1. Load model\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "llama_hf_model = AutoModelForCausalLM.from_pretrained(\n",
    "    hf_model,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quantization_config\n",
    ")\n",
    "\n",
    "# Load model tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(hf_model, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "if llama_hf_model and tokenizer:\n",
    "    print(f\"Hugging Face model and its tokenizer are loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cd6c2801-a8eb-4f33-959b-d1376736bdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading meta-llama/Llama-3.2-1B-Instruct model ...\n",
      "Hugging face pipeline created.\n",
      "meta-llama/Llama-3.2-1B-Instruct loaded.\n",
      "<langchain_community.vectorstores.faiss.FAISS object at 0x000002313D731C50> has been set-up as retriever.\n",
      "chat_history memroy has been set-up.\n",
      "\n",
      "Conversation chain is ready to be tested and used.\n",
      "CPU times: total: 422 ms\n",
      "Wall time: 1.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def setup_conversation_chain(model: str, vectorstores, temperature: float):\n",
    "    # 1. Set-up the model\n",
    "    if model == gpt_model:\n",
    "        llm = ChatOpenAI(temperature=temperature, model=gpt_model)\n",
    "        print(f\"{gpt_model} model loaded.\")\n",
    "        \n",
    "    elif model == llama_model:\n",
    "        llm = ChatOpenAI(temperature=temperature, model=llama_model, api_key=OLLAMA_API_KEY, base_url=OLLAMA_BASE_URL)\n",
    "        print(f\"{llama_model} model loaded.\")\n",
    "    \n",
    "    elif model == hf_model or (llama_hf_model is not None and tokenizer is not None):\n",
    "        print(f\"Loading {hf_model} model ...\")\n",
    "        \n",
    "        text_pipeline = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=llama_hf_model,\n",
    "            tokenizer=tokenizer,\n",
    "            max_new_tokens=512,\n",
    "            temperature=temperature,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            return_full_text=False\n",
    "        )\n",
    "        hf_llm = HuggingFacePipeline(pipeline=text_pipeline)\n",
    "        print(\"Hugging face pipeline created.\")\n",
    "        \n",
    "        llm = ChatHuggingFace(llm=hf_llm, model_id=hf_model)\n",
    "        print(f\"{hf_model} loaded.\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown or invalid model: {model}\")\n",
    "    \n",
    "    # 2. Set-up the retriever: the retriever is an abstraction over the VectorStore that will be used during RAG\n",
    "    retriever = vectorstores.as_retriever()\n",
    "    print(f\"{vectorstores} has been set-up as retriever.\")\n",
    "    \n",
    "    # 3. Set-up the conversation memory for the chat\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "    print(f\"chat_history memroy has been set-up.\")\n",
    "\n",
    "    # Putting it together: set-up the conversation chain with the GPT 4o-mini or Llama3.2, the vector store and memory\n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)\n",
    "    \n",
    "    return conversation_chain\n",
    "\n",
    "# Building custom conversation chain\n",
    "conversation_chain = setup_conversation_chain(\n",
    "    model=hf_model,\n",
    "    vectorstores=faiss_openai_vectorstores,\n",
    "    temperature=0.7\n",
    ")\n",
    "if conversation_chain:\n",
    "    print(\"\\nConversation chain is ready to be tested and used.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cf3a19-b3c9-4e48-bd6a-d4435c61166e",
   "metadata": {},
   "source": [
    "## Testing the Conversation Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d392ba-ba52-4087-865a-a98c8bde3367",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d49f5cd2-22e7-4ae2-97fa-cc1cebe7bdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name\t: gpt-4o-mini\n",
      "Retriever\t: Chroma using HuggingFaceEmbeddings\n",
      "\n",
      "Insurellm is an insurance tech startup founded by Avery Lancaster in 2015, aimed at disrupting the traditional insurance industry through innovative products. Its first offering, Markellm, is a marketplace that connects consumers with insurance providers. Since its inception, Insurellm has rapidly expanded, reaching 200 employees by 2024 and establishing 12 offices across the US.\n",
      "\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 2.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"Model name\\t: {conversation_chain.question_generator.llm.model_name}\")\n",
    "print(f\"Retriever\\t: {conversation_chain.retriever.tags[0]} using {conversation_chain.retriever.tags[1]}\\n\")\n",
    "\n",
    "message = \"Describe Insurellm in a few sentences\"\n",
    "response = conversation_chain.invoke({\"question\": message})\n",
    "print(f\"{response['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd84e74d-eee2-4fcc-b968-23e901b91b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name\t: gpt-4o-mini\n",
      "Retriever\t: Chroma using OpenAIEmbeddings\n",
      "\n",
      "Insurellm is an innovative insurance tech firm founded in 2015 by Avery Lancaster, specializing in disrupting the insurance industry with cutting-edge software products. The company offers four main products: Carllm for auto insurance, Homellm for home insurance, Rellm for reinsurance, and Markellm, a marketplace connecting consumers with insurance providers. With a workforce of 200 employees and over 300 clients worldwide, Insurellm is dedicated to transforming the landscape of insurance through innovation and reliability.\n",
      "\n",
      "CPU times: total: 172 ms\n",
      "Wall time: 4.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"Model name\\t: {conversation_chain.question_generator.llm.model_name}\")\n",
    "print(f\"Retriever\\t: {conversation_chain.retriever.tags[0]} using {conversation_chain.retriever.tags[1]}\\n\")\n",
    "\n",
    "message = \"Describe Insurellm in a few sentences\"\n",
    "response = conversation_chain.invoke({\"question\": message})\n",
    "print(f\"{response['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a0f5a21-28b0-4d71-b0c2-606782bcb2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name\t: gpt-4o-mini\n",
      "Retriever\t: FAISS using HuggingFaceEmbeddings\n",
      "\n",
      "Insurellm is an insurance technology startup founded in 2015 by Avery Lancaster, aimed at disrupting the insurance industry with innovative products. The company initially launched its first product, Markellm, which serves as a marketplace connecting consumers with insurance providers. By 2024, Insurellm had expanded significantly, reaching 200 employees and operating 12 offices across the United States.\n",
      "\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 3.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"Model name\\t: {conversation_chain.question_generator.llm.model_name}\")\n",
    "print(f\"Retriever\\t: {conversation_chain.retriever.tags[0]} using {conversation_chain.retriever.tags[1]}\\n\")\n",
    "\n",
    "message = \"Describe Insurellm in a few sentences\"\n",
    "response = conversation_chain.invoke({\"question\": message})\n",
    "print(f\"{response['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93d50f98-1845-474d-a7ce-60051bd49ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name\t: gpt-4o-mini\n",
      "Retriever\t: FAISS using OpenAIEmbeddings\n",
      "\n",
      "Insurellm is an innovative insurance tech firm founded in 2015 by Avery Lancaster, with a mission to disrupt the insurance industry through technology. The company offers four software products: Carllm for auto insurance, Homellm for home insurance, Rellm for the reinsurance sector, and Markellm, a marketplace connecting consumers with insurance providers. With a workforce of 200 employees and over 300 clients worldwide, Insurellm operates 12 offices across the US, focusing on delivering reliable and cutting-edge solutions for insurance companies.\n",
      "\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 4.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"Model name\\t: {conversation_chain.question_generator.llm.model_name}\")\n",
    "print(f\"Retriever\\t: {conversation_chain.retriever.tags[0]} using {conversation_chain.retriever.tags[1]}\\n\")\n",
    "\n",
    "message = \"Describe Insurellm in a few sentences\"\n",
    "response = conversation_chain.invoke({\"question\": message})\n",
    "print(f\"{response['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4afd28-6f30-406a-b470-3654e01c4723",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Ollama (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2f7bcf1-ac07-4f56-be28-d5a5a0b3cb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name\t: llama3.2:latest\n",
      "Retriever\t: Chroma using HuggingFaceEmbeddings\n",
      "\n",
      "I don't have much information on Insurellm beyond what's provided in our context. It appears to be an insurance technology company that offers various products and services, including a marketplace for consumers to connect with insurance providers. The company has expanded rapidly since its founding in 2015 and now has multiple offices across the US.\n",
      "\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 9.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"Model name\\t: {conversation_chain.question_generator.llm.model_name}\")\n",
    "print(f\"Retriever\\t: {conversation_chain.retriever.tags[0]} using {conversation_chain.retriever.tags[1]}\\n\")\n",
    "\n",
    "message = \"Describe Insurellm in a few sentences\"\n",
    "response = conversation_chain.invoke({\"question\": message})\n",
    "print(f\"{response['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5cb2276b-d6fe-4839-867c-f813d1b33b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name\t: llama3.2:latest\n",
      "Retriever\t: Chroma using OpenAIEmbeddings\n",
      "\n",
      "Insurellm is an innovative insurance tech firm that offers four software products: Carllm, Homellm, Rellm, and Markellm. Founded by Avery Lancaster in 2015, the company has rapidly expanded to become one of the leading players in the industry, serving over 300 clients worldwide with a team of 200 employees across 12 US offices. Insurellm is committed to disrupting the insurance industry through innovative products and services that prioritize reliability and customer care.\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 5.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"Model name\\t: {conversation_chain.question_generator.llm.model_name}\")\n",
    "print(f\"Retriever\\t: {conversation_chain.retriever.tags[0]} using {conversation_chain.retriever.tags[1]}\\n\")\n",
    "\n",
    "message = \"Describe Insurellm in a few sentences\"\n",
    "response = conversation_chain.invoke({\"question\": message})\n",
    "print(f\"{response['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "11cb83a8-12b0-49c6-8370-b862190cc3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name\t: llama3.2:latest\n",
      "Retriever\t: FAISS using HuggingFaceEmbeddings\n",
      "\n",
      "I don't know much about Insurellm from this context, but it appears to be an insurance technology company that offers various products and services aimed at disrupting the insurance industry. It was founded by Avery Lancaster in 2015 and has since expanded its presence with multiple offices across the US and a range of employees.\n",
      "\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 3.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"Model name\\t: {conversation_chain.question_generator.llm.model_name}\")\n",
    "print(f\"Retriever\\t: {conversation_chain.retriever.tags[0]} using {conversation_chain.retriever.tags[1]}\\n\")\n",
    "\n",
    "message = \"Describe Insurellm in a few sentences\"\n",
    "response = conversation_chain.invoke({\"question\": message})\n",
    "print(f\"{response['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "561035c5-51a5-48da-801f-513b4451aeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name\t: llama3.2:latest\n",
      "Retriever\t: FAISS using OpenAIEmbeddings\n",
      "\n",
      "Insurellm is an innovative insurance tech firm that offers four software products for various sectors of the industry, including auto, home, reinsurance, and marketplace solutions. Founded by Avery Lancaster in 2015, the company has rapidly expanded to become one of the leading players in the industry, serving over 300 clients worldwide with a team of 200 employees across 12 US offices.\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 5.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"Model name\\t: {conversation_chain.question_generator.llm.model_name}\")\n",
    "print(f\"Retriever\\t: {conversation_chain.retriever.tags[0]} using {conversation_chain.retriever.tags[1]}\\n\")\n",
    "\n",
    "message = \"Describe Insurellm in a few sentences\"\n",
    "response = conversation_chain.invoke({\"question\": message})\n",
    "print(f\"{response['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ab2f85-cd8b-4586-b8c4-7ba6367604ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Hugging Face Model & Tokenizer (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e9785d4a-3c4b-4be5-8a59-8bf306262a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name\t: meta-llama/Llama-3.2-1B-Instruct\n",
      "Retriever\t: Chroma using HuggingFaceEmbeddings\n",
      "\n",
      "Insurellm is an insurance technology (IT) startup that was founded in 2015 by Avery Lancaster. It offers a range of products, including a marketplace for insurance providers to connect with consumers, as well as a comprehensive training program to help customers utilize the services. Insurellm aims to revolutionize the insurance industry by providing innovative and user-friendly solutions to improve customer experience and increase efficiency.\n",
      "\n",
      "CPU times: total: 2.81 s\n",
      "Wall time: 3.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"Model name\\t: {conversation_chain.question_generator.llm.model_id}\")\n",
    "print(f\"Retriever\\t: {conversation_chain.retriever.tags[0]} using {conversation_chain.retriever.tags[1]}\\n\")\n",
    "\n",
    "message = \"Describe Insurellm in a few sentences\"\n",
    "response = conversation_chain.invoke({\"question\": message})\n",
    "print(f\"{response['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fa6e5545-da8a-45e6-bee5-9bc87d2ab0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name\t: meta-llama/Llama-3.2-1B-Instruct\n",
      "Retriever\t: Chroma using OpenAIEmbeddings\n",
      "\n",
      "Insurellm is an insurance tech firm that offers four insurance software products: Carllm for auto insurance, Homellm for home insurance, Rellm for the reinsurance sector, and Markellm for connecting consumers with insurance providers. Founded in 2015 by Avery Lancaster, Insurellm aims to disrupt the insurance industry by providing innovative products and solutions that prioritize both innovation and reliability for all insurance providers and customers.\n",
      "\n",
      "CPU times: total: 2.62 s\n",
      "Wall time: 3.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"Model name\\t: {conversation_chain.question_generator.llm.model_id}\")\n",
    "print(f\"Retriever\\t: {conversation_chain.retriever.tags[0]} using {conversation_chain.retriever.tags[1]}\\n\")\n",
    "\n",
    "message = \"Describe Insurellm in a few sentences\"\n",
    "response = conversation_chain.invoke({\"question\": message})\n",
    "print(f\"{response['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6388b5ee-235c-4699-92ed-89556170e506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name\t: meta-llama/Llama-3.2-1B-Instruct\n",
      "Retriever\t: FAISS using HuggingFaceEmbeddings\n",
      "\n",
      "Insurellm is an insurance tech startup that provides innovative solutions for the insurance industry. They were founded in 2015 by Avery Lancaster and have since expanded to become a leading provider of insurance marketplaces, connecting consumers with insurance providers. Their platform offers a range of products and services, including policy management, claims processing, and customer support, with a focus on improving the efficiency and customer experience of the insurance industry.\n",
      "\n",
      "CPU times: total: 2.67 s\n",
      "Wall time: 2.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"Model name\\t: {conversation_chain.question_generator.llm.model_id}\")\n",
    "print(f\"Retriever\\t: {conversation_chain.retriever.tags[0]} using {conversation_chain.retriever.tags[1]}\\n\")\n",
    "\n",
    "message = \"Describe Insurellm in a few sentences\"\n",
    "response = conversation_chain.invoke({\"question\": message})\n",
    "print(f\"{response['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "84bd3e0c-c4f3-404a-b78f-e18af7451152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name\t: meta-llama/Llama-3.2-1B-Instruct\n",
      "Retriever\t: FAISS using OpenAIEmbeddings\n",
      "\n",
      "Insurellm is an insurance technology (tech) firm that offers four insurance software products: Carllm, a car insurance portal; Homellm, a home insurance portal; Rellm, an enterprise platform for the reinsurance sector; and Markellm, a marketplace for connecting consumers with insurance providers. Founded in 2015, Insurellm has grown rapidly, reaching 200 employees and 300+ clients worldwide.\n",
      "\n",
      "CPU times: total: 2.55 s\n",
      "Wall time: 3.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"Model name\\t: {conversation_chain.question_generator.llm.model_id}\")\n",
    "print(f\"Retriever\\t: {conversation_chain.retriever.tags[0]} using {conversation_chain.retriever.tags[1]}\\n\")\n",
    "\n",
    "message = \"Describe Insurellm in a few sentences\"\n",
    "response = conversation_chain.invoke({\"question\": message})\n",
    "print(f\"{response['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fac090c-c1fd-48c7-8689-1786d8754b70",
   "metadata": {},
   "source": [
    "# UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "49aa9abd-6e04-4bf6-ac0f-469fd1c5887d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3.2:latest model loaded.\n",
      "<langchain_community.vectorstores.faiss.FAISS object at 0x000002313D5F7D50> has been set-up as retriever.\n",
      "chat_history memroy has been set-up.\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 1e+03 Î¼s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Using the best model and retriever\n",
    "conversation_chain = setup_conversation_chain(\n",
    "    model=llama_model,\n",
    "    vectorstores=faiss_hf_vectorstores,\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "def chat(message, history):\n",
    "    response = conversation_chain.invoke({\"question\": message})\n",
    "    return response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b0956104-b62e-4a84-9040-b5072736838d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view = gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ad5b20-251d-4c93-9b11-89626c263553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugface",
   "language": "python",
   "name": "hugface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
